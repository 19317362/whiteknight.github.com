---
layout: bloggerpost
title: IO Speedup, More Dramatic Still
publish: true
categories: [Parrot, IO]
---

Two days ago <a href="/2009/06/06/io_pudding_contains_proof.html.html">I talked about</a> how the speedups in the <a href="https://trac.parrot.org/parrot/browser/branches/io_rewiring">io_rewiring branch</a> were approaching 4x by some benchmarks. I posted an email to the list and got back a few replies which seemed to show the speedups were not so impressive as that. Specifically, <a href="http://groups.google.com/group/parrot-dev/msg/d986fcd098cdae6d">partcl</a> <a href="http://groups.google.com/group/parrot-dev/msg/3965173dae5ce2d5">didn't</a> appear to appreciate the work we've been doing, even if <a href="http://groups.google.com/group/parrot-dev/msg/a25b2d255c3d612d">Rakudo did</a>. No big deal, any speedups for any users would have been a win in my book, even if not all compilers on Parrot benefited from it. Some people winning is better then nobody winning. Luckily this isn't the end of the story.<br /><br />When <a href="http://irclog.perlgeek.de/parrot/2009-06-08#i_1221279">I logged on to IRC this morning</a>, Infinoid had a <a href="https://trac.parrot.org/parrot/changeset/39450">commit comming through</a> that would make everything better still. Here are some very impressive results that Infinoid has measured with his patch in place:<br /><pre><br />Infinoid> before: make coretest 84.97s user 61.91s system 32% cpu 7:35.52 total<br />Infinoid> after : make coretest 75.22s user 43.93s system 67% cpu 2:57.62 total<br />Whiteknight> so that's a factor-of-2 speedup on top of the 4x speedup that some<br />benchmarks are showing?<br />Whiteknight> Infinoid++ # Holy shit<br /></pre><br />That's right. In the branch, on top of the previous speedups we had, Infinoid has more then halved the running time of <code>make coretest</code>. This is a total of 8x speedup on the one benchmark that we had been using. However, this isn't even the most dramatic result. <a href="http://www.pmichaud.com/">pmichaud</a> had a doozie for us that I wouldn't have believed if I hadn't seen it (and I still might not believe it):<br /><pre><br />Infinoid> here's stats for pmichaud's benchmark:<br />Infinoid> trunk : ./parrot x.pir 12.37s user 1.67s system 56% cpu 24.747 total<br />Infinoid> branch: ./parrot x.pir 0.42s user 0.06s system 64% cpu 0.741 total<br /></pre><br />You read this correctly, at least one benchmark is running <i>50 times faster</i> in the branch now. As they say on the weight-loss commercials, "results not typical", but impressive nonetheless. More results:<br /><pre><br />Infinoid> trunk : make coretest 63.07s user 36.61s system 26% cpu 6:15.27 total<br />Infinoid> branch: make coretest  61.79s user 31.34s system 63% cpu 2:26.49 total<br /></pre><br />So what exactly was the culprit, the change that Infinoid was able to make that sped Parrot up by more then double? The problem, in a nutshell, was <a href="http://opengroup.org/onlinepubs/007908799/xsh/fsync.html"><code>fsync</code></a>. A number of IO API calls were using <code>Parrot_io_flush</code>, which internally would push the data to the OS <i>and</i> call <code>fsync</code> to ensure that the data was completely written to disk. This is unnecessary, and <code>fsync</code> was a huge slowdown. So what Infinoid did—brilliant in it's simplicity—was replace calls to <code>Parrot_io_flush</code> with calls to <code>Parrot_io_flush_buffer</code>, which would still write data out to the OS, but wouldn't call <code>fsync</code> anymore.<br /><br />So what exactly is <code>fsync</code> used for anyway?<br /><pre><br />szbalint> fsync only makes sense after accumulating a largish chunk of data anyways<br />Infinoid> fsync only makes sense for databases and mail servers ensuring atomicity<br /></pre><br />...and neither of these things are really part of the guarantee that Parrot's IO system makes to it's users. Parrot does not specify that it's basic IO will be atomic in any way, nor does it specify that we will force a disk write after so much data has been pushed through. We certainly could add an opt-in mode to guarantee that (especially if we can get some of the buffering code factored out like we are planning), but it isn't a requirement for all cases right now.<br /><br />So that's my little note this morning about our branch. Assuming testing keeps coming back positive, I'd like to get it merged in to trunk tonight so we can get started on the next round sometime after #parrotsketch tomorrow.
                <div class='old-blogger-comments'>
                    <h2 class='old-comment-header'>Comments</h3>
                
<div class='blogger-comment-div'>
    <a name='2911500810543437554'></a>
    <p class='blogger-comment-body'>
        My understanding is that the poor performance of fsync is implementation, not inherent. The recommmendation not to call fsync is largely an ext3 legacy. It's hard to argue with current realities, of course, but fsync() should be more useful and performant in the future.<br /><br />http://lwn.net/Articles/328363/<br />  Solving the ext3 latency problem<br /><br />http://lwn.net/Articles/327601/<br />  Linux Storage and Filesystem workshop<br /><br />http://lwn.net/Articles/326471/<br />  That massive filesystem thread
    </p>
    <div class='blogger-comment-author-div'>
        <span class='blogger-author-sig'><a class='blogger-author-uri' href='http://chrisdolan.livejournal.com/'>chrisdolan</a>
</span>
        <span class='blogger-comment-datestamp'>
            <a class='blogger-comment-link' href='{{ post.url }}#2911500810543437554'>
                6/9/2009 1:08:12 AM
            </a>
        </span>
    </div>
</div>
</div>
