---
layout: bloggerpost
title: Matrices
publish: true
categories: [Parrot, Matrixy, Parrot-Linear-Algebra]
---

Yesterday I put together a <a href="http://github.com/Whiteknight/parrot-linear-algebra/blob/master/src/pmc/nummatrix2d.pmc">prototype of a matrix PMC</a> for the <a href="http://github.com/Whiteknight/parrot-linear-algebra">parrot-linear-algebra </a>project. Today, it's building and can be used in Parrot, thanks to efforts from darbelo and desertm4x. It doesn't do much yet, since we haven't implemented many bindings for the CBLAS library. But it's a good way to store a 2-dimensional matrix of floating point numbers. The new PMC type, which I hope is only the first of many related PMCs, is called NumMatrix2D.<br /><br />Linear algebra is a big deal in the world of computing. When people talk about high performance computing, mathematical or scientific simulations, or other related topics, they're generally talking about applications involving linear algebra. Computer hardware optimizes for certain matrix and vector operations, and highly-tuned software libraries implement a wide set of other operations. Linear Algebra operations can be used to implement large sets of numerical algorithms. But, each matrix operation is composed of large numbers of scalar operations. For this reason, if we want to implement a linear algebra interface to Parrot, performance of the various primitive operations is critical.<br /><br /><a href="http://github.com/Whiteknight/matrixy">Matrixy</a> currently uses nested ResizablePMCArray PMCs to implement it's matrices. This is problematic for a number of reasons, and performance suffers significantly because of it. What I want to do soon, now that the NumMatrix2D builds, is to use it in Matrixy as the fundamental matrix data type. This should drastically improve performance and help to get rid of a lot of unnecessary code.<br /><br />Parrot-Linear-Algebra has a few things that it needs now. I'll discuss each separately.<br /><br /><span style="font-size:180%;">Be installable</span><br /><br />We need Parrot-Linear-Algebra to be installable so we can use the NumMatrix2D PMC type in other languages and projects easily. I tried a few naive things today, but obviously don't know enough about even my own platform to make this happen, much less to make it happen in many target platforms.<br /><br /><span style="font-size:180%;">Test Suite</span><br /><br />Now that we have something to test, we need to write a test suite. We want lots of tests so that we can keep track of regressions for NumMatrix2D, and maybe even do a little bit of proper Test-Driven-Development of new features.<br /><br />In general, I would really like to have the test harness be not written in Perl5. I would like to avoid Perl5 as a dependency throughout this project, and I would like to try to only rely on Parrot and languages which run on Parrot. <s>To my knowledge, nobody has yet written a complete test harness that runs on top of Parrot, so that may have to be a new project I start work on soon.</s><br /><br />[<b>Update 27 Oct 2009:</b> I've been informed by dukeleto that Plumage in fact has <a href="http://gitorious.org/parrot-plumage/parrot-plumage/blobs/master/t/harness">a test harness written in pure NQP</a>. I plan to "borrow" that later for both Matrixy and Parrot-Linear-Algebra.]<br /><br /><span style="font-size:180%;">More BLAS Bindings</span><br /><br />The goal for Parrot-Linear-Algebra, at least as of the last "meeting" I had with some of the other committers, was that we were going to try to build BLAS bindings into the NumMatrix2D PMC itself, and add separate NCI bindings for other libraries (LAPACK, etc).<br /><br />Some of the API functions will fit neatly into VTABLEs: add, substract, multiply. Others will need to be made into METHODs instead. This gives us lots of flexibility while keeping the most common operations fast.<br /><br /><span style="font-size:180%;">BLAS Detection</span><br /><br />At the moment, we don't do any automatic detection of BLAS or one of it's various implementations. What we need to do is write a series of configure probes that will look for various implementations and generate the necessary interfaces automatically. We would like to support CBLAS, ATLAS, and GSL directly, if possible. Other implementations (and believe me, there are many) would be great too. Since BLAS is critical for high-performance computing and computing benchmarks, there are many implementations which are tuned and optimized for individual processor types. We want to support the common types initially, but provide enough flexibility that people could implement new probes for other similar libraries as needed.<br /><br /><span style="font-size:180%;">Road Ahead</span><br /><br />There is obviously a lot of work left to do, but we've made the important first few steps already. Highly performant matrix types and bindings to optimized linear algebra libraries will open the door for all sorts of high-performance computing applications to start targetting Parrot. It will also, of course, remove some roadblocks from Matrixy development. Anybody who's interested in joining the effort should feel free to get in touch here, via email, or on IRC.