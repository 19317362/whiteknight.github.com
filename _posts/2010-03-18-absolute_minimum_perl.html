---
layout: bloggerpost
title: Absolute Minimum Perl
---

I've been slowly brewing an idea in my head for several weeks now, and I think this is finally the time to start talking about it.<br /><br />When I first wrote Parrot-Linear-Algebra and Parrot-Data-Structures, I wrote their test suites in Patrick Michaud's NQP. Actually, the "NQP" I used at first was really just a thin wrapper around routines written in PIR, but the infrastructure was present. NQP is a really great language for doing things like this: It's far superior to PIR in terms of readability and usability, and has a lot of cool features. Sure, it's not exactly the vaunted Perl 6, but it has a lot going for it and is quickly becoming the defacto development language of choice for many compiler and project devs in the Parrot ecosystem. Recently Austin Hasting's Kakapo library has progressed to the point where it is starting to get really awesome itself, and is filling in a lot of the capability holes that Parrot doesn't fill itself.  Two of his biggest recent achievements, a high-level unit testing suite and a mock object library, finally pushed me over the edge. I've gone back through and rewritten all the PLA tests using proper NQP using Kakapo's unit testing framework. With the new framework I'm able to write tests faster and inherit behavioral tests common to all types into all test files. Code coverage has increased dramatically, and the end product is far nicer.<br /><br />Within the next week I'm hoping to give the same treatment to PDS as well.<br /><br />One problem I have identified with NQP/Kakapo, however, is that execution speed of my tests is <span style="font-style: italic;">way down<span style="font-weight: bold;">.</span></span> I mean, the tests run much slower now. Some of this has to do with parsing speed and the time it takes to load in the kakapo library, and I'm sure I can do better about cherry-picking which features to load so I can avoid some unnecessary overhead. But the real problem that I am seeing is the bloated PIR code that NQP generates. First, let's start with a code example:<br /><br />my $foo := "hello world";<br />say($foo);<br /><br />Which produces this PIR output code:<br /><br />.namespace []<br />.sub "_block11"  :anon :subid("10_1268925505.4982")<br />.annotate "line", 1<br />    new $P13, "Undef"<br />    .lex "$foo", $P13<br />    new $P14, "String"<br />    assign $P14, "hello world"<br />    store_lex "$foo", $P14<br />.annotate "line", 2<br />    find_lex $P15, "$foo"<br />    $P16 = "say"($P15)<br />.annotate "line", 1<br />    .return ($P16)<br />.end<br /><br />This sure is a lot of work just to print one string. I will note that a more succinct program of "say('hello world');" actually does the same with much much much less output code as we would expect, but I'm purposefully showing a worse example to make a point.<br /><br />If we look at the code above, we immediately see a few things. First, when we declare the variable $foo we autovivify it to create a new Undef PMC. We create a lexical entry for this variable, create a new String PMC, set the value of the String to the literal "hello world", and store the String to the lexical $foo. This is just line one.<br /><br />On line two, we then lookup the value of the lexical $foo and pass that to the "say" function.<br /><br />Finally, because this is Perl, we implicitly return the value of the last statement in the block. In this case, we're taking whatever the return value of the say function is, which I assume is nothing important.<br /><br />In terms of PIR, even if we insisted on storing the value of a string into a PMC register for equivalence, and if we insisted on calling the method "say" instead of the PIR opcode of the same name, we would still only end up with this small snippet of code to perform the same operation:<br /><br />$P0 = box "hello world"<br />"say"($P0)<br /><br />So on a naive comparison it appears that NQP produces a huge amount of code bloat to do something which can be done reasonably in two lines of PIR.<br /><br />Of course we can't quite be naive about it. NQP does what it does for a reason. We need to use lexicals because NQP supports closures, and there's no good way to access variables by name in a closure without being diligent about storing values in the lexical scope. Let's show a short contrived example:<br /><br />my $foo := "hello";<br />&#123;<br />my $bar := " world";<br />say($foo ~ $bar);<br />&#125;<br /><br />...and the PIR listing:<br /><br />.namespace []<br />.sub "_block11"  :anon :subid("10_1268926740.38234")<br />.annotate "line", 0<br />    .const 'Sub' $P16 = "11_1268926740.38234"<br />    capture_lex $P16<br />.annotate "line", 1<br />    new $P13, "Undef"<br />    .lex "$foo", $P13<br />    new $P14, "String"<br />    assign $P14, "hello"<br />    store_lex "$foo", $P14<br />.annotate "line", 2<br />    .const 'Sub' $P16 = "11_1268926740.38234"<br />    capture_lex $P16<br />    $P23 = $P16()<br />.annotate "line", 1<br />    .return ($P23)<br />.end<br /><br /><br />.namespace []<br />.sub "_block15"  :anon :subid("11_1268926740.38234") :outer("10_1268926740.38234")<br />.annotate "line", 3<br />    new $P17, "Undef"<br />    .lex "$bar", $P17<br />    new $P18, "String"<br />    assign $P18, " world"<br />    store_lex "$bar", $P18<br />.annotate "line", 4<br />    find_lex $P19, "$foo"<br />    find_lex $P20, "$bar"<br />    concat $P21, $P19, $P20<br />    $P22 = "say"($P21)<br />.annotate "line", 2<br />    .return ($P22)<br />.end<br /><br /><br />We see a lot more of the same jump-through-hoops code to manage lexicals, and we see that the curly brackets define a nested lexical scope which itself is a separate subroutine. Again, the equivalent PIR code, if we wanted to do a similar approach with two variables, would be this:<br /><br />$P0 = box "hello"<br />$P1 = box " world"<br />$P2 = concat $P0, $P1<br />"say"($P2)<br /><br />So there's a huge amount of procedural overhead in NQP that we need to live with so we can support some of the more complicated features of the language.<br /><br />But the question pops up: what if we don't need closures? If we don't need closures, and don't need to include support for them, we can be very aggressive about optimizing away some of this bloat. In fact, I think we can be aggressive to the point of not using <span style="font-style: italic;">any</span> lexical variables and never using nested lexical scopes. If we know that a variable is assigned to before it is ever used, we can also avoid unnecessary autovivification hoops. In fact, a diligent programmer armed with reasonable error messages and enough discipline could turn off autovivification behavior entirely and completely avoid the expenditure.<br /><br />Let me now show another slightly longer example:<br /><br />sub baz($foo) &#123;<br />        my $bar := " world";<br />        return($foo ~ $bar);<br />&#125;<br /><br />...and the PIR:<br /><br />.namespace []<br />.sub "_block11"  :anon :subid("10_1268927369.92095")<br />.annotate "line", 0<br />    .const 'Sub' $P13 = "11_1268927369.92095"<br />    capture_lex $P13<br />.annotate "line", 1<br />    .const 'Sub' $P13 = "11_1268927369.92095"<br />    capture_lex $P13<br />    .lex "baz", $P13<br />    find_lex $P24, "baz"<br />    .return ($P24)<br />.end<br /><br /><br />.namespace []<br />.sub "baz"  :subid("11_1268927369.92095") :outer("10_1268927369.92095")<br />    .param pmc param_16<br />.annotate "line", 1<br />    new $P15, 'ExceptionHandler'<br />    set_addr $P15, control_14<br />    $P15."handle_types"(58)<br />    push_eh $P15<br />    .lex "$foo", param_16<br />.annotate "line", 2<br />    new $P17, "Undef"<br />    .lex "$bar", $P17<br />    new $P18, "String"<br />    assign $P18, " world"<br />    store_lex "$bar", $P18<br />.annotate "line", 3<br />    find_lex $P19, "$foo"<br />    find_lex $P20, "$bar"<br />    concat $P21, $P19, $P20<br />    $P22 = "return"($P21)<br />.annotate "line", 1<br />    .return ($P22)<br />  control_14:<br />    .local pmc exception<br />    .get_results (exception)<br />    getattribute $P23, exception, "payload"<br />    .return ($P23)<br />.end<br /><br />We see here even more interesting though slightly annoying code. The function "return"() throws a control exception which would have the effect of unwinding any nested lexical scopes if we were trying to return from inside one of them. This is why the last few lines of the baz function appear to be an exception handler. It's because they are, indeed, an exception handler to catch and control these return exceptions.<br /><br />If we knew that we never had to deal with closures or other advanced features like that, we could get rid of lexical variable management, and we could get rid of nested lexical scopes. Without nested lexical scopes, and without other "advanced" options like being able to override the returns mechanism, we could get rid of calls to the "return"() function and uses of exceptions to perform returns. If we knew that we weren't relying on autovivification behavior or implicit return values in our code, we could get rid of them as well.<br /><br />In fact, if we were willing to make a few semantic sacrifices, the code generated by the NQP compiler could be 75% smaller or more, and we have to believe it would be similarly faster to execute as well. I can tell you that the Matrixy compiler, for instance, doesn't need these features, and I suspect that there would be other compiler designers around the Parrot-verse who would be willing to shut them off if it meant significant performance gains.<br /><br />All that remains is a question of how to implement these ideas. I've considered making a fork of NQP and ripping out everything that I don't need, but that seems like a waste. Far better, in my mind, would be to work within the NQP project itself and create some optional optimization stages that could be used to rip out unwanted code bloat in the code generated by NQP itself. This would mean a smaller, faster compiler, and I think many people might appreciate that.<br /><br /><br />